{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch 0{\n",
      "\tdeep: 0\n",
      "\tnum of samples for each class: 3 : 1 \n",
      "\tsplit by dim 0\n",
      "\tbranch 0->0{\n",
      "\t\tdeep: 1\n",
      "\t\tnum of samples for each class: 2 : 1 \n",
      "\t\tclass: 0\n",
      "\t}\n",
      "\tbranch 0->1{\n",
      "\t\tdeep: 1\n",
      "\t\tnum of samples for each class: 1 \n",
      "\t\tclass: 0\n",
      "\t}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "import data\n",
    "import utils as Util\n",
    "\n",
    "class DecisionTree():\n",
    "    def __init__(self):\n",
    "        self.clf_name = \"DecisionTree\"\n",
    "        self.root_node = None\n",
    "\n",
    "    def train(self, features, labels):\n",
    "        # features: List[List[float]], labels: List[int]\n",
    "        # init\n",
    "        assert (len(features) > 0)\n",
    "        features_unique = [np.unique(f) for f in np.array(features).T]\n",
    "        features = np.array(features).tolist()\n",
    "\n",
    "        # build the tree\n",
    "        self.root_node = TreeNode(features, labels, features_unique)\n",
    "        if self.root_node.splittable:\n",
    "            self.root_node.split()\n",
    "        return\n",
    "\n",
    "    def predict(self, features):\n",
    "        # features: List[List[any]]\n",
    "        # return List[int]\n",
    "        y_pred = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            pred = self.root_node.predict(feature)\n",
    "            y_pred.append(pred)\n",
    "        return y_pred\n",
    "\n",
    "class TreeNode(object):\n",
    "    def __init__(self, features, labels, features_unique):\n",
    "        # features: List[List[any]], labels: List[int], features_unique: List[List[any]]\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.children = []\n",
    "        self.features_unique = features_unique\n",
    "        # find the most common labels in current node\n",
    "        count_max = 0\n",
    "        for label in np.unique(labels):\n",
    "            if self.labels.count(label) > count_max:\n",
    "                count_max = labels.count(label)\n",
    "                self.cls_max = label\n",
    "                # splitable is false when all features belongs to one class\n",
    "        if len(np.unique(labels)) < 2 or len(np.array(self.features).T) < 1:\n",
    "            self.splittable = False\n",
    "        else:\n",
    "            self.splittable = True\n",
    "\n",
    "        self.dim_split = None  # the index of the feature to be split\n",
    "\n",
    "        self.feature_uniq_split = None  # the possible unique values of the feature to be split\n",
    "\n",
    "    #TODO: try to split current node\n",
    "    def split(self):\n",
    "        feature_information_gains = []\n",
    "        unique_labels, unique_label_count = np.unique(self.labels, return_counts=True)\n",
    "        \n",
    "        for f in range(len(np.array(self.features).T)):\n",
    "            feature_class_count = [[len([i for i,j in zip(np.array(self.features)[:,f], np.array(self.labels)) if i==feature \n",
    "                                and j==label]) for label in unique_labels] for feature in self.features_unique[f]]\n",
    "            Entropy = sum([(-1)*(float(x)/sum(unique_label_count))*np.log2(float(x)/sum(unique_label_count)) \n",
    "                                for x in unique_label_count])\n",
    "            feature_information_gains.append((Util.Information_Gain(Entropy, feature_class_count), len(np.unique(np.array(self.features)[:,f]))))\n",
    "                      \n",
    "        information_gains = np.array([i[0] for i in feature_information_gains])\n",
    "        if all(information_gains==0.0):\n",
    "            self.splittable = False\n",
    "            return\n",
    "        \n",
    "        self.dim_split = feature_information_gains.index(max(feature_information_gains, key=lambda x: (x[0], x[1])))\n",
    "        feature_labels = np.column_stack((self.features, self.labels)).tolist()\n",
    "\n",
    "        feature_labels.sort(key= lambda x: x[self.dim_split])\n",
    "        feature_unique, unique_index= np.unique(np.array(feature_labels)[:,self.dim_split], return_index=True)\n",
    "        feature_class_split = np.split(feature_labels, unique_index[1:])\n",
    "        self.feature_uniq_split = self.features_unique[self.dim_split]\n",
    "\n",
    "        self.feature_uniq_split = self.feature_uniq_split.tolist()\n",
    "        self.feature_uniq_split.sort()\n",
    "        feature_unique = feature_unique.tolist()\n",
    "        \n",
    "        for i in range(len(self.feature_uniq_split)):\n",
    "            if not self.feature_uniq_split[i] in feature_unique:\n",
    "                new_child = TreeNode([[]], self.labels, [[]])\n",
    "                new_child.cls_max = self.cls_max\n",
    "                self.children.append(new_child) \n",
    "            else:\n",
    "                index = feature_unique.index(self.feature_uniq_split[i])   \n",
    "                child_labels = feature_class_split[index][:,-1]\n",
    "                child_features = np.delete(feature_class_split[index],-1, 1)\n",
    "                child_features = np.delete(child_features, self.dim_split, 1)\n",
    "                child_features_unique = np.delete(self.features_unique, self.dim_split, 0)\n",
    "                new_child = TreeNode(child_features.tolist(), child_labels.astype(int).tolist(), child_features_unique)\n",
    "                self.children.append(new_child)\n",
    "                if new_child.splittable:\n",
    "                    new_child.split()\n",
    "        \n",
    "    # TODO: predict the branch or the class\n",
    "    def predict(self, feature):\n",
    "        # feature: List[any]\n",
    "        # return: intâ‰¥\n",
    "        if not self.splittable:\n",
    "            return self.cls_max\n",
    "        else:            \n",
    "            split_child = self.children[self.feature_uniq_split.index(feature[self.dim_split])]\n",
    "            feature = np.delete(np.array(feature), self.dim_split)\n",
    "            return split_child.predict(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
